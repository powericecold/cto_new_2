# Airflow Configuration
AIRFLOW_HOME=/opt/airflow
AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
AIRFLOW__CORE__LOGS_FOLDER=/opt/airflow/logs
AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres:5432/airflow
AIRFLOW_UID=50000
AIRFLOW_GID=50000

# Airflow Webserver Port
AIRFLOW_WEBSERVER_PORT=8080

# Database Configuration
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
POSTGRES_PORT=5432

# Hive Configuration
HIVE_METASTORE_DB=hive_metastore
HIVE_METASTORE_USER=hive
HIVE_METASTORE_PASSWORD=hive
HIVE_METASTORE_HOST=postgres-hive
HIVE_METASTORE_PORT=5432
HIVE_WAREHOUSE_DIR=/user/hive/warehouse
HIVESERVER2_PORT=10000

# Spark Configuration
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8081
SPARK_WORKER_PORT=8081
SPARK_WORKER_WEBUI_PORT=8082

# Hadoop HDFS Configuration
HDFS_NAMENODE_PORT=9000
HDFS_NAMENODE_WEBUI_PORT=9870
HDFS_DATANODE_PORT=9864
HDFS_DATANODE_WEBUI_PORT=9864
HDFS_REPLICATION=1
HDFS_BLOCKSIZE=134217728

# Jupyter Configuration
JUPYTER_PORT=8888
JUPYTER_TOKEN=jupyter_token
JUPYTER_ALLOW_ROOT=true

# Data Paths (mounted in containers)
DATA_MOUNT_PATH=/data
NOTEBOOKS_MOUNT_PATH=/notebooks
SCRIPTS_MOUNT_PATH=/scripts

# Resource Limits
CPU_LIMIT=2.0
MEMORY_LIMIT=2g
MEMORY_RESERVATION=1g
